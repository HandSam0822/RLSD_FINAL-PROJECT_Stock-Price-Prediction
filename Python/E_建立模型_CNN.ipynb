{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# import keras\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "from keras.layers import (Dense, Activation, Flatten, Conv2D, \n",
    "                          MaxPooling2D,Dropout,BatchNormalization)\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TSMC_NEWS = pd.read_csv('/Users/liaoshousan/Desktop/大四上/R語言與資料科學導論/Final_PROJECT-StockPrice Prediction/做好所有預處理的新聞/TSMC_NEWS.csv')\n",
    "TSMC_PRICE = pd.read_csv('/Users/liaoshousan/Desktop/大四上/R語言與資料科學導論/Final_PROJECT-StockPrice Prediction/做好所有預處理的股價/TSMC_Stock.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = []\n",
    "for NEWS in TSMC_NEWS['CONTENT']:\n",
    "    NEWS = re.sub(r'[。，（）_?\\d]','',NEWS)\n",
    "    #這邊想再加一行過濾亂碼的條件，但是還沒搞懂\n",
    "    seg_list = jieba.cut(NEWS)\n",
    "    token = ' '.join(NEWS)\n",
    "    token_list.append(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/liaoshousan/Desktop/大四上/R語言與資料科學導論/Final_PROJECT-StockPrice Prediction/兩千個重要正負面詞彙/token_2000.txt\", \"r\") as f:\n",
    "    token_2000 = f.read().splitlines()\n",
    "\n",
    "token_2000 = list(set(token_2000))\n",
    "count_vec = CountVectorizer(vocabulary=token_2000)\n",
    "token_matrix = count_vec.fit_transform(token_list)\n",
    "token_array = pd.DataFrame(token_matrix.toarray(),columns = token_2000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([TSMC_NEWS,token_array],axis = 1)\n",
    "X = X.sort_values(by = 'TIME')\n",
    "y = X['收盤價']\n",
    "X = X.drop(columns=['TITLE','TIME','DESCRIPTION','CONTENT','status','漲跌價差','成交筆數','status','收盤價'],axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = np.array(X)\n",
    "X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建神經網路模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_modelCNN():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(128,activation ='relu',\n",
    "                    kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "from keras.layers import LSTM\n",
    "def baseline_model_RNN():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(\n",
    "        input_dim=X.shape[2],\n",
    "        output_dim = 50,\n",
    "        return_sequences = True))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(\n",
    "        100,\n",
    "        return_sequences = False))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(\n",
    "        output_dim = 1))\n",
    "    model.add(Activation('linear'))\n",
    "              \n",
    "    # Compile model\n",
    "    model.compile(loss = 'mse', optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liaoshousan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/liaoshousan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(return_sequences=True, input_shape=(None, 200..., units=50)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/liaoshousan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1)`\n",
      "/Users/liaoshousan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, None, 50)          410200    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 50)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 470,701\n",
      "Trainable params: 470,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3495 samples, validate on 1499 samples\n",
      "Epoch 1/50\n",
      "3495/3495 [==============================] - 3s 840us/step - loss: 56928.9108 - val_loss: 55835.2377\n",
      "Epoch 2/50\n",
      "3495/3495 [==============================] - 1s 355us/step - loss: 54244.4125 - val_loss: 52040.3501\n",
      "Epoch 3/50\n",
      "3495/3495 [==============================] - 1s 256us/step - loss: 50334.5760 - val_loss: 48031.6147\n",
      "Epoch 4/50\n",
      "3495/3495 [==============================] - 1s 254us/step - loss: 46801.3850 - val_loss: 44727.7338\n",
      "Epoch 5/50\n",
      "3495/3495 [==============================] - 1s 252us/step - loss: 43852.2111 - val_loss: 41974.9107\n",
      "Epoch 6/50\n",
      "3495/3495 [==============================] - 1s 249us/step - loss: 41336.2363 - val_loss: 39580.4143\n",
      "Epoch 7/50\n",
      "3495/3495 [==============================] - 1s 253us/step - loss: 39073.3957 - val_loss: 37435.1531\n",
      "Epoch 8/50\n",
      "3495/3495 [==============================] - 1s 252us/step - loss: 36984.2831 - val_loss: 35475.6220\n",
      "Epoch 9/50\n",
      "3495/3495 [==============================] - 1s 339us/step - loss: 35023.0554 - val_loss: 33662.9018\n",
      "Epoch 10/50\n",
      "3495/3495 [==============================] - 1s 355us/step - loss: 33307.5595 - val_loss: 31967.1461\n",
      "Epoch 11/50\n",
      "3495/3495 [==============================] - 1s 377us/step - loss: 31669.8522 - val_loss: 30378.3051\n",
      "Epoch 12/50\n",
      "3495/3495 [==============================] - 1s 410us/step - loss: 30135.3102 - val_loss: 28874.1895\n",
      "Epoch 13/50\n",
      "3495/3495 [==============================] - 1s 360us/step - loss: 28582.9796 - val_loss: 27450.5223\n",
      "Epoch 14/50\n",
      "3495/3495 [==============================] - 1s 300us/step - loss: 27202.7956 - val_loss: 26093.6560\n",
      "Epoch 15/50\n",
      "3495/3495 [==============================] - 1s 282us/step - loss: 25953.0085 - val_loss: 24805.0357\n",
      "Epoch 16/50\n",
      "3495/3495 [==============================] - 1s 280us/step - loss: 24583.7099 - val_loss: 23572.4093\n",
      "Epoch 17/50\n",
      "3495/3495 [==============================] - 1s 322us/step - loss: 23343.9135 - val_loss: 22396.3343\n",
      "Epoch 18/50\n",
      "3495/3495 [==============================] - 2s 447us/step - loss: 22312.3794 - val_loss: 21273.4784\n",
      "Epoch 19/50\n",
      "3495/3495 [==============================] - 1s 350us/step - loss: 21242.2122 - val_loss: 20199.4969\n",
      "Epoch 20/50\n",
      "3495/3495 [==============================] - 1s 357us/step - loss: 20135.3232 - val_loss: 19169.4565\n",
      "Epoch 21/50\n",
      "3495/3495 [==============================] - 2s 430us/step - loss: 19161.5261 - val_loss: 18185.5450\n",
      "Epoch 22/50\n",
      "3495/3495 [==============================] - 1s 379us/step - loss: 18059.3637 - val_loss: 17243.6061\n",
      "Epoch 23/50\n",
      "3495/3495 [==============================] - 2s 516us/step - loss: 17125.5050 - val_loss: 16342.7242\n",
      "Epoch 24/50\n",
      "3495/3495 [==============================] - 1s 343us/step - loss: 16343.7452 - val_loss: 15477.7743\n",
      "Epoch 25/50\n",
      "3495/3495 [==============================] - 2s 444us/step - loss: 15398.1249 - val_loss: 14651.9261\n",
      "Epoch 26/50\n",
      "3495/3495 [==============================] - 1s 428us/step - loss: 14572.7819 - val_loss: 13862.8319\n",
      "Epoch 27/50\n",
      "3495/3495 [==============================] - 1s 344us/step - loss: 13886.4814 - val_loss: 13105.5057\n",
      "Epoch 28/50\n",
      "3495/3495 [==============================] - 1s 417us/step - loss: 13151.6725 - val_loss: 12382.8190\n",
      "Epoch 29/50\n",
      "3495/3495 [==============================] - 1s 297us/step - loss: 12419.1427 - val_loss: 11691.7904\n",
      "Epoch 30/50\n",
      "3495/3495 [==============================] - 1s 277us/step - loss: 11636.9881 - val_loss: 11031.8169\n",
      "Epoch 31/50\n",
      "3495/3495 [==============================] - 2s 433us/step - loss: 11016.2304 - val_loss: 10403.0430\n",
      "Epoch 32/50\n",
      "3495/3495 [==============================] - 1s 326us/step - loss: 10400.2284 - val_loss: 9802.5422\n",
      "Epoch 33/50\n",
      "3495/3495 [==============================] - 1s 315us/step - loss: 9850.5905 - val_loss: 9228.9631\n",
      "Epoch 34/50\n",
      "3495/3495 [==============================] - 1s 303us/step - loss: 9305.4401 - val_loss: 8682.6198\n",
      "Epoch 35/50\n",
      "3495/3495 [==============================] - 1s 297us/step - loss: 8762.7592 - val_loss: 8162.0291\n",
      "Epoch 36/50\n",
      "3495/3495 [==============================] - 1s 341us/step - loss: 8165.3694 - val_loss: 7669.0937\n",
      "Epoch 37/50\n",
      "3495/3495 [==============================] - 1s 361us/step - loss: 7829.1903 - val_loss: 7198.2940\n",
      "Epoch 38/50\n",
      "3495/3495 [==============================] - 1s 337us/step - loss: 7409.7151 - val_loss: 6751.4297\n",
      "Epoch 39/50\n",
      "3495/3495 [==============================] - 1s 297us/step - loss: 6949.0321 - val_loss: 6326.2777\n",
      "Epoch 40/50\n",
      "3495/3495 [==============================] - 1s 309us/step - loss: 6555.0303 - val_loss: 5922.9846\n",
      "Epoch 41/50\n",
      "3495/3495 [==============================] - 1s 325us/step - loss: 6193.2454 - val_loss: 5539.5681\n",
      "Epoch 42/50\n",
      "3495/3495 [==============================] - 1s 322us/step - loss: 5766.6726 - val_loss: 5180.1144\n",
      "Epoch 43/50\n",
      "3495/3495 [==============================] - 1s 265us/step - loss: 5449.1077 - val_loss: 4839.0610\n",
      "Epoch 44/50\n",
      "3495/3495 [==============================] - 1s 271us/step - loss: 5145.1890 - val_loss: 4517.3939\n",
      "Epoch 45/50\n",
      "3495/3495 [==============================] - 1s 257us/step - loss: 4815.2604 - val_loss: 4213.8048\n",
      "Epoch 46/50\n",
      "3495/3495 [==============================] - 1s 278us/step - loss: 4378.4448 - val_loss: 3929.0706\n",
      "Epoch 47/50\n",
      "3495/3495 [==============================] - 1s 270us/step - loss: 4256.9668 - val_loss: 3659.7514\n",
      "Epoch 48/50\n",
      "3495/3495 [==============================] - 1s 268us/step - loss: 3948.9895 - val_loss: 3408.1148\n",
      "Epoch 49/50\n",
      "3495/3495 [==============================] - 1s 265us/step - loss: 3773.2197 - val_loss: 3170.6870\n",
      "Epoch 50/50\n",
      "3495/3495 [==============================] - 1s 341us/step - loss: 3455.5757 - val_loss: 2950.7538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a600f6a90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = baseline_model_RNN()\n",
    "model.summary()\n",
    "model.fit(X_train,y_train,batch_size = 64,nb_epoch = 50,validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[189.40115],\n",
       "       [189.40115],\n",
       "       [189.40115],\n",
       "       ...,\n",
       "       [189.40115],\n",
       "       [189.40115],\n",
       "       [189.40115]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)\n",
    "# prediction = LSTM.predict_sequence_multiple(model,X_test,50,50)\n",
    "# LSTM.plot_results_multiple(prediction,y_test,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "為什麼用神經網路都會預測一樣的數字？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d611551277ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='center right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='center right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 發現資料筆數差距太大了，讓模型整個爛掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
