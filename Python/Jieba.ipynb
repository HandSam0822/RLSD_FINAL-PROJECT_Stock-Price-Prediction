{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讀取的檔案，已經涵蓋了新聞的正負面屬性，今天我們希望找出每篇新聞的關鍵字  \n",
    "因此除了要做結巴切詞之外，同時也希望得到tf-idf等等資訊  \n",
    "不過再這之前，我們希望對新聞資訊做一些處理(處理亂碼、標點符號、停用詞等等)  \n",
    "更進階一點，為了讓結巴切的準確一些，我們可以新增字典，讓結巴沒看過的詞彙也分的出來   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LARGAN_NEWS = pd.read_csv('/Users/liaoshousan/Desktop/大四上/RLSD 期末專案/大立光正負新聞.csv')\n",
    "Foxconn_NEWS = pd.read_csv('/Users/liaoshousan/Desktop/大四上/RLSD 期末專案/鴻海正負新聞.csv')\n",
    "TSMC_NEWS = pd.read_csv('/Users/liaoshousan/Desktop/大四上/RLSD 期末專案/台積電正負新聞.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正則表達式把文章弄得好看一點"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 切割出重要詞彙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(df):\n",
    "\n",
    "    upnews = df[df['status']==1]\n",
    "    downnews = df[df['status']==-1]\n",
    "    \n",
    "    positive_token = []\n",
    "    for goodnews in upnews['CONTENT']:\n",
    "        goodnews = re.sub(r'[。，（）]','',goodnews)\n",
    "        #這邊想再加一行過濾亂碼的條件，但是還沒搞懂\n",
    "        seg_list = jieba.cut_for_search(news)\n",
    "        token = ' '.join(seg_list)\n",
    "        positive_token.append(token)\n",
    "    \n",
    "    count_vec=CountVectorizer() \n",
    "    good_news_count = count_vec.fit_transform(positive_token) \n",
    "    good_news_count = pd.DataFrame(good_news_count.toarray(),columns = count_vec.get_feature_names())\n",
    "    #這兩行如果不做的話，concat起來會因為index不同而出現NaN\n",
    "    good_news_count.reset_index(drop=True, inplace=True)  \n",
    "    upnews.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    positive_news = pd.concat([upnews,good_news_count],axis = 1)\n",
    "\n",
    "    \n",
    "    negative_token = []\n",
    "    for badnews in downnews['CONTENT']:\n",
    "        badnews = re.sub(r'[。，（）]','',badnews)\n",
    "        seg_list = jieba.cut_for_search(badnews)\n",
    "        token = ' '.join(seg_list)\n",
    "        negative_token.append(token)\n",
    "    \n",
    "    count_vec=CountVectorizer() \n",
    "    bad_news_count = count_vec.fit_transform(negative_token) \n",
    "    bad_news_count = pd.DataFrame(bad_news_count.toarray(),columns = count_vec.get_feature_names())\n",
    "    \n",
    "    bad_news_count.reset_index(drop=True, inplace=True)  \n",
    "    downnews.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    negative_news = pd.concat([downnews,bad_news_count],axis = 1)\n",
    "    \n",
    "    return positive_news,negative_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_Foxconn_NEWS = cut(Foxconn_NEWS)[0]\n",
    "negative_Foxconn_NEWS = cut(Foxconn_NEWS)[1]\n",
    "positive_LARGAN_NEWS = cut(LARGAN_NEWS)[0]\n",
    "negative_LARGAN_NEWS = cut(LARGAN_NEWS)[1]\n",
    "positive_TSMC_NEWS = cut(TSMC_NEWS)[0]\n",
    "negative_TSMC_NEWS = cut(TSMC_NEWS)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_Foxconn_NEWS.to_csv('/Users/liaoshousan/Desktop/大四上/RLSD 期末專案/鴻海正面新聞.csv')\n",
    "negative_Foxconn_NEWS.to_csv('/Users/liaoshousan/Desktop/大四上/RLSD 期末專案/鴻海負面新聞.csv')\n",
    "positive_LARGAN_NEWS.to_csv('/Users/liaoshousan/Desktop/大四上/RLSD 期末專案/大立光正面新聞.csv')\n",
    "negative_LARGAN_NEWS.to_csv('/Users/liaoshousan/Desktop/大四上/RLSD 期末專案/大立光負面新聞.csv')\n",
    "positive_TSMC_NEWS.to_csv('/Users/liaoshousan/Desktop/大四上/RLSD 期末專案/台積電正面新聞.csv')\n",
    "negative_TSMC_NEWS.to_csv('/Users/liaoshousan/Desktop/大四上/RLSD 期末專案/台積電負面新聞.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
