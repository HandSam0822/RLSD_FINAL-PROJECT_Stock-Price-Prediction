{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讀取的檔案，已經涵蓋了新聞的正負面屬性，今天我們希望找出每篇新聞的關鍵字  \n",
    "因此除了要做結巴切詞之外，同時也希望得到tf-idf等等資訊  \n",
    "不過再這之前，我們希望對新聞資訊做一些處理(處理亂碼、標點符號、停用詞等等)  \n",
    "更進階一點，為了讓結巴切的準確一些，我們可以新增字典，讓結巴沒看過的詞彙也分的出來   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/Users/liaoshousan/Desktop/\\xe5\\xa4\\xa7\\xe5\\x9b\\x9b\\xe4\\xb8\\x8a/RLSD \\xe6\\x9c\\x9f\\xe6\\x9c\\xab\\xe5\\xb0\\x88\\xe6\\xa1\\x88/\\xe5\\xa4\\xa7\\xe7\\xab\\x8b\\xe5\\x85\\x89\\xe6\\xad\\xa3\\xe8\\xb2\\xa0\\xe6\\x96\\xb0\\xe8\\x81\\x9e.csv' does not exist: b'/Users/liaoshousan/Desktop/\\xe5\\xa4\\xa7\\xe5\\x9b\\x9b\\xe4\\xb8\\x8a/RLSD \\xe6\\x9c\\x9f\\xe6\\x9c\\xab\\xe5\\xb0\\x88\\xe6\\xa1\\x88/\\xe5\\xa4\\xa7\\xe7\\xab\\x8b\\xe5\\x85\\x89\\xe6\\xad\\xa3\\xe8\\xb2\\xa0\\xe6\\x96\\xb0\\xe8\\x81\\x9e.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4a573aec880d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLARGAN_NEWS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/liaoshousan/Desktop/大四上/RLSD 期末專案/大立光正負新聞.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mFoxconn_NEWS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/liaoshousan/Desktop/大四上/RLSD 期末專案/鴻海正負新聞.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTSMC_NEWS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/liaoshousan/Desktop/大四上/RLSD 期末專案/台積電正負新聞.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/Users/liaoshousan/Desktop/\\xe5\\xa4\\xa7\\xe5\\x9b\\x9b\\xe4\\xb8\\x8a/RLSD \\xe6\\x9c\\x9f\\xe6\\x9c\\xab\\xe5\\xb0\\x88\\xe6\\xa1\\x88/\\xe5\\xa4\\xa7\\xe7\\xab\\x8b\\xe5\\x85\\x89\\xe6\\xad\\xa3\\xe8\\xb2\\xa0\\xe6\\x96\\xb0\\xe8\\x81\\x9e.csv' does not exist: b'/Users/liaoshousan/Desktop/\\xe5\\xa4\\xa7\\xe5\\x9b\\x9b\\xe4\\xb8\\x8a/RLSD \\xe6\\x9c\\x9f\\xe6\\x9c\\xab\\xe5\\xb0\\x88\\xe6\\xa1\\x88/\\xe5\\xa4\\xa7\\xe7\\xab\\x8b\\xe5\\x85\\x89\\xe6\\xad\\xa3\\xe8\\xb2\\xa0\\xe6\\x96\\xb0\\xe8\\x81\\x9e.csv'"
     ]
    }
   ],
   "source": [
    "LARGAN_NEWS = pd.read_csv('/Users/liaoshousan/Desktop/RLSD_PROJECT-StockPrice Prediction/提取出正負面的新聞/大立光正負新聞.csv')\n",
    "Foxconn_NEWS = pd.read_csv('/Users/liaoshousan/Desktop/RLSD_PROJECT-StockPrice Prediction/提取出正負面的新聞/大立光正負新聞.csv\n",
    "TSMC_NEWS = pd.read_csv('/Users/liaoshousan/Desktop/大四上/RLSD 期末專案/台積電正負新聞.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正則表達式把文章弄得好看一點"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 切割出重要詞彙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(df):\n",
    "\n",
    "    upnews = df[df['status']==1]\n",
    "    downnews = df[df['status']==-1]\n",
    "    \n",
    "    positive_token = []\n",
    "    for goodnews in upnews['CONTENT']:\n",
    "        goodnews = re.sub(r'[。，（）]','',goodnews)\n",
    "        #這邊想再加一行過濾亂碼的條件，但是還沒搞懂\n",
    "        seg_list = jieba.cut_for_search(news)\n",
    "        token = ' '.join(seg_list)\n",
    "        positive_token.append(token)\n",
    "    \n",
    "    count_vec=CountVectorizer() \n",
    "    good_news_count = count_vec.fit_transform(positive_token) \n",
    "    good_news_count = pd.DataFrame(good_news_count.toarray(),columns = count_vec.get_feature_names())\n",
    "    #這兩行如果不做的話，concat起來會因為index不同而出現NaN\n",
    "    good_news_count.reset_index(drop=True, inplace=True)  \n",
    "    upnews.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    positive_news = pd.concat([upnews,good_news_count],axis = 1)\n",
    "\n",
    "    \n",
    "    negative_token = []\n",
    "    for badnews in downnews['CONTENT']:\n",
    "        badnews = re.sub(r'[。，（）]','',badnews)\n",
    "        seg_list = jieba.cut_for_search(badnews)\n",
    "        token = ' '.join(seg_list)\n",
    "        negative_token.append(token)\n",
    "    \n",
    "    count_vec=CountVectorizer() \n",
    "    bad_news_count = count_vec.fit_transform(negative_token) \n",
    "    bad_news_count = pd.DataFrame(bad_news_count.toarray(),columns = count_vec.get_feature_names())\n",
    "    \n",
    "    bad_news_count.reset_index(drop=True, inplace=True)  \n",
    "    downnews.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    negative_news = pd.concat([downnews,bad_news_count],axis = 1)\n",
    "    \n",
    "    return positive_news,negative_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_Foxconn_NEWS = cut(Foxconn_NEWS)[0]\n",
    "negative_Foxconn_NEWS = cut(Foxconn_NEWS)[1]\n",
    "positive_LARGAN_NEWS = cut(LARGAN_NEWS)[0]\n",
    "negative_LARGAN_NEWS = cut(LARGAN_NEWS)[1]\n",
    "positive_TSMC_NEWS = cut(TSMC_NEWS)[0]\n",
    "negative_TSMC_NEWS = cut(TSMC_NEWS)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_Foxconn_NEWS.to_csv('/Users/liaoshousan/Desktop/大四上/RLSD 期末專案/鴻海正面新聞.csv')\n",
    "negative_Foxconn_NEWS.to_csv('/Users/liaoshousan/Desktop/大四上/RLSD 期末專案/鴻海負面新聞.csv')\n",
    "positive_LARGAN_NEWS.to_csv('/Users/liaoshousan/Desktop/大四上/RLSD 期末專案/大立光正面新聞.csv')\n",
    "negative_LARGAN_NEWS.to_csv('/Users/liaoshousan/Desktop/大四上/RLSD 期末專案/大立光負面新聞.csv')\n",
    "positive_TSMC_NEWS.to_csv('/Users/liaoshousan/Desktop/大四上/RLSD 期末專案/台積電正面新聞.csv')\n",
    "negative_TSMC_NEWS.to_csv('/Users/liaoshousan/Desktop/大四上/RLSD 期末專案/台積電負面新聞.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
